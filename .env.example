# Copy this file to .env and fill in the values.
#   cp .env.example .env
#
# Then start everything with a single command:
#   docker compose up --build

# ---------------------------------------------------------------------------
# LLM provider (required)
# ---------------------------------------------------------------------------

# Provider: openai | azure | openrouter | vllm | sglang
LLM_PROVIDER=openai

# Model identifier as recognised by the chosen provider
LLM_MODEL=gpt-4.1-mini

# API key for the provider
LLM_API_KEY=sk-...

# Custom base URL (leave blank for the default provider endpoint)
# LLM_BASE_URL=

# Azure OpenAI API version (Azure only)
# LLM_API_VERSION=2024-02-01

# ---------------------------------------------------------------------------
# LLM sampling parameters (optional — defaults shown)
# ---------------------------------------------------------------------------
# LLM_TEMPERATURE=1.0
# LLM_TOP_P=1.0
# LLM_MAX_NEW_TOKENS=16384
# LLM_MAX_INPUT_TOKENS=120000
# LLM_REASONING_EFFORT=          # low | medium | high (o-series models)

# ---------------------------------------------------------------------------
# Optional — networking
# ---------------------------------------------------------------------------

# Host port the app (frontend) is served on. Default: 8000
# APP_PORT=8000

# ---------------------------------------------------------------------------
# Optional — heavy build dependencies
# Set to "true" before running "docker compose build" to include them.
# These are excluded by default to keep the image small.
#
#   INSTALL_R=true       ~50 MB  adds R interpreter + rpy2
#                                enables R-language agent sessions and
#                                running R in the browser terminal
#
#   INSTALL_DOCLING=true ~3 GB   adds Docling + PyTorch
#                                enables PDF / document ingestion in the agent
# ---------------------------------------------------------------------------
# INSTALL_R=false
# INSTALL_DOCLING=false
